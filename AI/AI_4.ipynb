{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e7e05d",
   "metadata": {},
   "source": [
    "# AI모델 활용 4주차\n",
    "\n",
    "## 4-1 생성형 AI모델 직접 만들기 때 주의!!\n",
    "\n",
    "### 생성형AI란?\n",
    "- 주어진 입력에 따라 새로운 콘텐츠를 생성하는 인공지능 기술\n",
    "- 몇 개의 단어를 입력받아 그에 맞는 문장 생성, 스케치를 바탕으로 이미지 생성 \n",
    "\n",
    "#### 종류\n",
    "1. 텍스트 생성(GPT-3, ChatGPT 등)\n",
    "2. 이미지 생성(DALL-E, Stable Diffusion 등)\n",
    "3. 음악 생성(Magenta 등)\n",
    "\n",
    "#### 어려움\n",
    "1. 대규모 데이터 필요\n",
    "2. 컴퓨터 자원의 한계\n",
    "3. 모델 구조의 복잡성\n",
    "4. 훈련 과정의 불안정성\n",
    "\n",
    "#### 파인튜닝의 필요성!\n",
    "- 파인 튜닝은 사전 학습된 모델을 특정 작업에 맞게 추가로 학습시키는 과정으로, 생성형 AI 모델을 보다 쉽게 적용할 수 있는 방법\n",
    "- 사전 학습된 모델(시간 절감, 높은 성능, 도메인 특화, 작업 맞춤)\n",
    "\n",
    "#### 만들 때 고려할 부분\n",
    "1. 사전학습된 모델 활용\n",
    "2. 클라우드 서비스 활용\n",
    "3. 작은 프로젝트부터 시작하기\n",
    "\n",
    "\n",
    "\n",
    "## 4-2 생성형 AI모델 기본 원리\n",
    "\n",
    "### 랜덤성 Randomness\n",
    "\n",
    "#### 역할\n",
    "- 출력 데이터를 생성할 때 일정한 확률에 따라 다양한 선택지를 고려하게 한다.\n",
    "\n",
    "#### 확률 분포\n",
    "- 학습 데이터를 통해 얻은 확률 분포를 기반으로 새로운 데이터를 생성\n",
    "- 데이터의 분포를 학습해서 새로운 데이터를 생성할 수 있게 되는거다.\n",
    "\n",
    "### 조건성 Conditionality\n",
    "\n",
    "#### 조건 입력\n",
    "- 입력된 조건에 따라 결과를 다르게 생성\n",
    "- 텍스트, 이미지, 오디오 등 다양한 형식의 조건이 있다.\n",
    "\n",
    "#### 중요성\n",
    "- 조건성 덕분에 생성형 모델은 매우 다양한 상황에 적응할 수 있다.(사용자가 원하는 특정 스타일, 주제, 분위기 등)\n",
    "\n",
    "### 결론\n",
    "- 생성형 AI는 랜덤성과 조건성을 결합하여 다양한 결과를 생성한다.\n",
    "- 조건은 출력의 전반적인 틀과 스타일을 결정\n",
    "- 랜덤성은 결과의 세부적인 변화를 만든다.\n",
    "- 두 요소의 상호작용 덕분에 생성형 AI는 창의적이고 예측 불가능한 결과를 생성가능하게 만들어 준다.\n",
    "\n",
    "### ※작동원리\n",
    "\n",
    "#### 텍스트 기반 생성형 모델의 원리\n",
    "1. 입력 토큰화\n",
    "2. 확률 예측\n",
    "3. 랜덤 선택: temperature 파라미터를 조정하여 랜덤성을 조절가능\n",
    "4. 반복 생성\n",
    "\n",
    "#### 이미지 기반 생성형 모델의 원리\n",
    "1. 텍스트 인코딩\n",
    "2. 이미지 생성\n",
    "3. 세부 사항 추가\n",
    "\n",
    "#### 오디오 기반 생성형 모델의 원리\n",
    "1. 텍스트 또는 멜로디 인코딩\n",
    "2. 오디오 생성\n",
    "3. 랜덤성 적용\n",
    "\n",
    "\n",
    "## 4-3 Hugging Face와 Stable Diffusion\n",
    "\n",
    "### 텍스트 생성\n",
    "1. 사전학습된 모델 사용\n",
    "2. 서비스를 활용해서 AIP의 형태로 언어를 형성\n",
    "\n",
    "#### GPT-4o 모델로 텍스트 생성하기\n",
    "\n",
    "> API_KEY는 설정 파일이나 환경변수를 통해 관리해야한다. (코드상에 KEY작성 금지!!)\n",
    "\n",
    "### Stable Diffusion을 활용한 이미지 생성\n",
    "\n",
    "#### Stable Diffusion 모델의 세부 조정\n",
    "- **guidance_scale**: 텍스트 조건을 얼마나 강하게 반영할지 결정하는 파라미터. 값이 높을수록 텍스트 설명에 충실한 이미지를 생성한다.\n",
    "- **num_inference_steps**: 이미지 생성 과정에서의 추론 단계 수를 지정한다. 단계 수가 많을수록 이미지의 품질이 향상되지만, 생성 시간이 길어진다.\n",
    "\n",
    "```python\n",
    "image = pipe(prompt, guidance_scale=7.5, num_inference_steps=50).images[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e0af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, we found those who had gone into the world to have more faith in, and to be more willing to change, our minds. For I believe in the power I have brought to life, which I have in the world.\n"
     ]
    }
   ],
   "source": [
    "# 4-3\n",
    "# 1. 사전학습된 모델 사용\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model = \"gpt2\")\n",
    "\n",
    "generated_text = generator(\"Once upon a time\", max_length=50, num_return_sequences=1)\n",
    "\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545de9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3\n",
    "# 2. 서비스를 활용해서 AIP의 형태로 언어를 형성\n",
    "\n",
    "# JavaScript에 openai환경변수 설정\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<your OpenAI API key>\"\n",
    "\n",
    "# python\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # 필요되는 정보들\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕?\"}  \n",
    "  ]\n",
    ")\n",
    "\n",
    "print(\"답변: \" + completion.choices[0].message.content)\n",
    "\n",
    "# 안녕하세요! 만나서 반가워요. 저랑 얘기하다가 재미 없으면 이렇게 생각해보세요: 적어도 엉덩이에 꼬리 달린 원숭이와는 다르게, 저는 평범하게 무리하지 않거든요! 뭐든 물어보세요, 도와드릴게요! 😄 \n",
    "\n",
    "# 강사의 한마디: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3 강의 13분 코드 해석\n",
    "# stable diffusion 모델 예제 코드\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Stable Diffusion 파이프라인 로드\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")  # GPU 사용\n",
    "\n",
    "# 텍스트 설명을 기반으로 이미지 생성\n",
    "prompt = \"A futuristic cityscape with flying cars at sunset\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# 생성된 이미지 저장 및 출력\n",
    "image.save(\"generated_image.png\")\n",
    "image.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Onesword",
   "language": "python",
   "name": "onesword"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
