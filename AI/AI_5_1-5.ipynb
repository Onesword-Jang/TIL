{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4199f76e",
   "metadata": {},
   "source": [
    "# AI모델 활용 5주차 (1 ~ 5)\n",
    "\n",
    "## ☑️ 5-1 API 심화 및 간단한 실습\n",
    "\n",
    "### 🔎 모델 서빙이란?\n",
    "- 학습된 머신러닝 모델을 실제 애플리케이션에서 사용하게 제동\n",
    "- 서빙된 모델은 외부에서 입력 데이터를 박아 예측을 수행하고 응답을 반환 한다.\n",
    "\n",
    "1) RESTful API 개념\n",
    "- REST(Representational State Transfer)아케텍처 스타일을 따르는 API올 HTTP를 통해 클라이언트와 서버 간의 데이터를 주고받는 방식\n",
    "- 자원: 시스템에서 자원은 URL로 고유하게 식별 된다.\n",
    "- HTTP메서드: 이를 활용해서 자원에 대한 작업을 수행 (각 메서드는 특정 작업을 나타내니 작업의 종류에 따라 호출해야한다.)\n",
    "- 구상태성 (Statelessness): 클라이언트와 서버 간의 모든 요청은 독립적, 서버는 각 요청을 별도로 처리(클라이언트의 상태를 서버가 기억하지 않음)\n",
    "- 표현: 클라이언트가 자원을 요청할 때 서버는 자원의 현재 상태를 표현한 데이터를 받아낸다.\n",
    "\n",
    "2) FAST API\n",
    "- 아키텍쳐를 따르지 않고 python에서 RESTful API를 구축하는데 편한 패키지\n",
    "- 서버를 동작 시키지는 않음(웹프레임 워크라서 API와 라우팅 등의 기능만 제공)\n",
    "- 실제 요청 처리와 소통은 서버(유비콘)에서 한다.\n",
    "\n",
    "3) RESTful의 메서드\n",
    "- GET: 서버에서 데이터를 가져온다\n",
    "- POST: 서버에 데이터를 보낸다.\n",
    "- PUT: 서버의 데이터를 업데이트 한다.\n",
    "- DELETE: 서버의 데이터를 삭제한다.\n",
    "\n",
    "### *** 실습 중 만난 문제***\n",
    "#### 1. FastAPI 서버 실행 부분에서 ipynb파일을 바로 실행 시킬 수 없음 (FastAPI를 정의한 app을 찾을 수 없다고  Error가 나옴)\n",
    "\n",
    "> FastAPI를 사용할 땐 py파일을 만들어 사용하거나 vscode에서 만들면 쉽다.\n",
    "\n",
    "> 쥬피터 노트북에서 사용하는 3가지 방법이있다.\n",
    "\n",
    "1) 매직 명령어 사용\n",
    "\n",
    "```python\n",
    "%%writefile AI_5.py\n",
    "from fastapi import FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"Hello\": \"World\"}\n",
    "```\n",
    "2) subprocess 사용\n",
    "```python\n",
    "import subprocess\n",
    "subprocess.run([\"uvicorn\", \"AI_5:app\", \"--reload\"])\n",
    "```\n",
    "- 이 방법은 Uvicorn 프로세스에 점유되어 다른 셀을 사용할 수 없는 한계가 있다.\n",
    "\n",
    "3) 별도 터미널에서 실행\n",
    "- 일반 터미널이나 Anaconda Prompt에서 FastAPI를 실행하는 것이 가장 간편한 방법\n",
    "- Jupyter Notebook은 FastAPI 서버와 독립적으로 사용할 수 있어, 서버 실행에 영향을 받지 않는다.\n",
    "\n",
    "4) 쥬피터 노프북 셀에서 사용 방법은 ***3번 째 코드***\n",
    "\n",
    "#### ***2. port의 종류***\n",
    "\n",
    "8000 : 테스트 용\n",
    "\n",
    "Well-Known Ports(0-1023): 이 범위의 포트는 표준화된 프로토콜에 의해 사용\n",
    "\n",
    "* 80 : HTTP\n",
    "- 443 : HTTPS\n",
    "- 25 : SMTP\n",
    "- 21 : FTP\n",
    "\n",
    "Registered Ports (1024-49151): 이 범위는 특정 애플리케이션에 의해 등록되어 사용\n",
    "\n",
    "- 3306 : MySQL\n",
    "- 5432 : PostgreSQL\n",
    "\n",
    "Dynamic/Private Ports (49152-65535): 이 범위의 포트는 동적으로 할당되는 포트로, 일반적으로 클라이언트 애플리케이션이 서버에 연결할 때 임시로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "pip install fastai\n",
    "pip install fastapi uvicorn\n",
    "pip install fastapi uvicorn nest_asyncio\n",
    "\n",
    "uvicorn AI_5:app --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77364ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "# FastAPI\n",
    "%%writefile AI_5.py\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# FastAPI의 인스턴스를 통해 get메서드 정의\n",
    "# 해당 Url로 get메서드가 호출 되게 되면 resd_root가 실해되고 해당함수가 반환하는게 결과값\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return{\"message\": \"hello world\"}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cabf82a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [22676]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:62957 - \"GET / HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [22676]\n"
     ]
    }
   ],
   "source": [
    "# 쥬피터 노트북 셀에서 FastAPI 실행\n",
    "\n",
    "from fastapi import FastAPI\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "# nest_asyncio 적용 (Jupyter Notebook에서 비동기 이벤트 루프 충돌 방지)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# FastAPI 앱 인스턴스 생성\n",
    "app = FastAPI()\n",
    "\n",
    "# 라우트 설정 예시\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"no no world\"}\n",
    "\n",
    "# Uvicorn 서버 실행 함수\n",
    "def run():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "\n",
    "# 서버 실행\n",
    "run()\n",
    "\n",
    "# host와 port는 설절하지 않으면 기본적으로 127.0.0.1, 8000으로 설정 된다.\n",
    "# 127.0.0.1은 로컬 머신에서만 접근 가능하게 만드는 설정\n",
    "# 0.0.0.0으로 설정하면 외부에서 서버에 접근 가능(해당 서버의 IP주소를 통해 접근 가능)\n",
    "# port는 IP 주소와 함께 사용되어, 네트워크 상에서 어떤 서비스에 연결할지를 결정하는 역할\n",
    "# 8000은 개발 및 테스트 용도로 널리 사용되는 비표준 포트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b49231",
   "metadata": {},
   "source": [
    "## ☑️ 5-2 chatGPT 호출 (실습없음)\n",
    "\n",
    "### 🔎 Open AI API란?\n",
    "* OpenAI에서 제공하는 다양한 인공지능 모델을 쉽게 사용할 수 있도록 해주는 API\n",
    "- ChatGPT는 자연스러운 대화를 생성하는 데 사용되며, 이를 통해 챗봇이나 고객 지원 시스템 등을 구축할 수 있다.\n",
    "\n",
    "### 1. OpenAI 호출 단계\n",
    "1. OpenAI 계정 생성 및 로그인\n",
    "2. API키 발급 (API호출에는 비용이 발생하기 때문에 보안이 철저하게 해야한다.)\n",
    "3. API호출 환경 설정 (필요 라이브러리 설치)\n",
    "4. ChatGPT API 키 등록하기(프롬프트나 터미널)\n",
    "> 환경변수로 등록! export OPENAI_API_KEY=\"바로 여기에!\"\n",
    "5. API호출 결과 처리\n",
    "\n",
    "### 2. API 키 관리 방법\n",
    "1. **환경변수에 저장:** 애플리케이션이 실행 될 때 참고해서 읽어오는 방법\n",
    "2. **.env파일 사용:** .env파일에 API키와 같은 민감 정보를 저장(어플리케이션에서 load해서 사용), 버젼 관리 시스템에서 제외 되어야 한다.\n",
    "3. **시크릿 매니지먼트 서비스 사용:** 클라우드나 비밀관리 서비스를 사용해서 API키를 저장하고 애플리케이션에서 안전하게 접근하는 방법\n",
    "4. **CICD시스템:** 배포 파이프라인에서 민감 데이터를 보호, 자동화된 배포 프로세스에 통합되어있어 실수가 적다.\n",
    "5. API키를 애플리케이션 구성파일에 **암호화** 시킨다.\n",
    "\n",
    "\n",
    "-------------\n",
    "\n",
    "## ☑️ 5-3 ChatGPT와 ElevenLabs 실습\n",
    "\n",
    "### ElevenLabs 주의점\n",
    "- 이미 학습된 모듈이있고 파인튜닝으로 내 목소리로 사용 가능(모듈이 노출 되면 보이스피싱에 조심해야함)\n",
    "- 파인 튜닝은 유료\n",
    "- requests 라이브러리 사용\n",
    "- 코드를 실행 될 때 임포메이션에 중요 정보가있어 실행화면 노출에 조심해야한다.\n",
    "\n",
    "-------------------\n",
    "\n",
    "## ☑️ 5-4 YOLO를 활용한 이미지 객체 탐지\n",
    "\n",
    "### 🔎 YOLO란?\n",
    "- 이미지에서 객체의 위치, 종류를 동시에 예측\n",
    "- 실시간 처리가 가능할 정도로 매우 빠름\n",
    "- 높은 정확도\n",
    "- CNN 기반\n",
    "\n",
    "### 작동 순서\n",
    "- 하나의 이미지가 들어왔을 때 그리드로 분할한다.\n",
    "- 각 그리드들은 b개의 바운딩 박스를 예측하게 된다.(중심 좌표와 너비, 높이, 정확도, 특정 클래스에 속할 확율이 나온다.)\n",
    "- 클래스 화율 예측(각 그리드 셀을 c개의 클래스에대한 확률 예측, 그리드 셀이 객체를 포함한다고 했을 때 해당 객체가 특정 클래스에 포함될 확율)\n",
    "- 이 클래스 확율은 이미지 전체에서 객체가 특정 객체에 포함되는지 예측\n",
    "- mns: 여러개의 바운딩 박스가 하나의 객체를 탐지한 경우 중복된 박스를 제거하고 가장 신뢰도가 높은 박스만 남기는 과정\n",
    "\n",
    "### 실습 중 만난 문제\n",
    "\n",
    "#### 1. numpy와 ultralytics의 컴파일러 문제와 빌드도구(meson)의 경로 관련 오류 \n",
    "이 문제는 주로 Visual Studio C++ 빌드도구가 누락되어 발생한다.\n",
    "\n",
    "##### 해결방법\n",
    "https://visualstudio.microsoft.com/ko/visual-cpp-build-tools/\n",
    "1. Visual Studio C++ 빌드 도구 설치(설치 중 \"Windows용 C++ CMake tools\" 같이 다운하면 좋음)\n",
    "2. 사전 빌드된 numpy설치 (1.24.3)\n",
    "3. 설치 재시도(사전 빌드 numpy설치 후)\n",
    "\n",
    "--------\n",
    "\n",
    "## ☑️ 5-5 FastAI: 사전 학습된 모델 사용해보기\n",
    "\n",
    "### ResNet의 사전 학습된 모델 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bf5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-3 질의응답형 ChatGPT AI 생성\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕?\"}  \n",
    "  ]\n",
    ")\n",
    "\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b8108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-3 대화형태 ChatGPT AI 생성\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 초기 시스템 명령어 설정\n",
    "system_message = {\n",
    "    \"role\":\"system\", \"content\":\"너는 친구야, 나에게 술 친구가 되어서 인생상담을 해줘\"\n",
    "}\n",
    "\n",
    "# 대화 내용을 저장할 공간 생성\n",
    "messages = [system_message]\n",
    "# 또는 정보를 저장 가능\n",
    "messages = [system_message,\n",
    "           {\"role\":\"user\",\"content\":\"내 이름은 장한검\"}\n",
    "           {\"role\":\"user\",\"content\":\"직업은 백수\"}\n",
    "           {\"role\":\"user\",\"content\":\"코딩을 배우는 중\"}]\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"사용자 전달:\")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"대답: 좋은 대화였어.. 잘가!!\")\n",
    "        braek\n",
    "        \n",
    "    # 대화내용을 ChatGPT에게 제공\n",
    "    messages.append({\"role\":\"user\",\"content\":user_input})\n",
    "    completion = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        messages = messages\n",
    "    )\n",
    "    \n",
    "    \n",
    "    reply = completion.choices[0].message.content\n",
    "    print(\"대답: \" + reply )\n",
    "    # massage에 대답 넣기(gpt가 대화 내역 인지)\n",
    "    messages.append({\"role\":\"assistant\",\"content\":reply})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-3 음성 생성 ElevenLabs AI 실습\n",
    "\n",
    "# bash\n",
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-3 음성 생성 ElevenLabs AI 실습\n",
    "\n",
    "# python\n",
    "import os\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import io\n",
    "\n",
    "# .env 파일에서 API 키와 URL을 가져오는 방법\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "url = os.getenv(\"APL_URL\")\n",
    "\n",
    "# 설정 가능 변수\n",
    "output_filename = \"output_audio.mp3\"\n",
    "\n",
    "headers = {\n",
    "    \"xi-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# 코드로 API키와 URL가져오기\n",
    "output_filename = \"output_audio.mp3\"\n",
    "\n",
    "url = \"모델 URL\"\n",
    "headers = {\n",
    "    \"xi-api-key\": \"API - KEY\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# 사용자에게 입력 받기\n",
    "text = input(\"텍스트를 입력하세요: \")\n",
    "\n",
    "# 음성 데이터 요청\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"model_id\": \"eleven_multilingual_v2\",\n",
    "    \"voice_settings\": {\n",
    "        # 얼마나 변화없이 아나운서 처럼 읽은 것인지(0.3 이하는 추천하지 않음)\n",
    "        \"stability\": 0.3,\n",
    "        # 목소리의 유사도를 설정\n",
    "        \"similarity_boost\": 1,\n",
    "        # 설하는 사람의 억양을 얼마나 따라 갈지(스타일을 낮추어야지 다른 나라언어를 적용했을 때 좋다.)\n",
    "        \"style\": 1,\n",
    "        \"use_speaker_boost\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# 리퀘스트 라이브러리를 통해 host에 해당하는 호출을 한다.\n",
    "# data와 headers를 전달한다.\n",
    "# stream=True는 응답 데이터를 스트리밍 방식으로 받는지 설정\n",
    "response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "\n",
    "# 응답코드를 설정\n",
    "# 200은 HTTP 상태코들르 나타내는데 API유통이 성공했을 때 200이 나타난다.\n",
    "if response.status_code == 200:\n",
    "    # b\"\" 오디오 문자열이 바이트 단위여서 바이트 단위를 초기화해준다.\n",
    "    audio_content = b\"\"\n",
    "    # 청크단위로 읽어와 응답데이터 처리\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            audio_content += chunk\n",
    "\n",
    "    # AudioSegment는 pydub의 패키지\n",
    "    # 바이트 데이터를 io.BytesIO를 사용해서 메모리 파일 객체로 변환한 뒤 \n",
    "    # from_mp3를 사용해서 mo3파일로 바꾼다.\n",
    "    segment = AudioSegment.from_mp3(io.BytesIO(audio_content))\n",
    "    # 변환된 오디오를 지정한 파일 이름, 형식으로 저장한다\n",
    "    segment.export(output_filename, format=\"mp3\")\n",
    "    print(f\"Success! Wrote audio to {output_filename}\")\n",
    "\n",
    "    # 오디오를 재생합니다.\n",
    "    # Play도 pydub의 패키지\n",
    "    play(segment)\n",
    "else:\n",
    "    print(f\"Failed to save file: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5806cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-4 ChatGPT 이미지 생성\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = input(\"prompt:\")\n",
    "\n",
    "# client.images.generate 메서드를 사용해 이미지 생성을 요청\n",
    "response = client.images.generate(\n",
    "    # \"dall-e-3\"로 모델 지정\n",
    "    model = \"dall-e-3\",\n",
    "    # 생성할 이미지의 설명, input으로 지정\n",
    "    prompt=prompt,\n",
    "    # 이미지의 해상도를 설정\n",
    "    size=\"1024x1024\",\n",
    "    # \"hd\"는 고화질 이미지 설정\n",
    "    quality=\"hd\",\n",
    "    # 생성할 이미지 개수 지정\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "# data[0]은 이미지 생성 개수를 1로 지정해 놓았기 때문\n",
    "# 여러개일 경우 특정 부분을 지목해도 되고 슬라이싱 형식으로 지정 가능 \n",
    "image_url = response.data[0].url\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-4 YOLO 이미지 생성\n",
    "\n",
    "# bash\n",
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-4 YOLO 이미지 생성\n",
    "\n",
    "# python\n",
    "from ultralytics import YOLO\n",
    "import cv2 # 이미지, 시각트리에 강력\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# YOLOv8 도델 로드\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = 'cat.jpeg'\n",
    "\n",
    "# 이미지를 모델에 입력하여 객체 탐지 수행\n",
    "results = model(image_path)\n",
    "\n",
    "# 탐지결과 출력\n",
    "result = results[0]\n",
    "\n",
    "# 탐지된 객체들이 표시된 이미지를 가져옴\n",
    "# 바운딩 박스는 탐지된 객체를 둘러싸는 직사각형\n",
    "ima_with_boxes = result.plot() # result.plot()은 바운딩 박스가 포함된 이미지를 변환\n",
    "\n",
    "# matplotlib을 사용해서 이미지를 가져옴\n",
    "plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff099680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-5 ResNet의 사전 학습된 모델 사용하기\n",
    "\n",
    "# bash\n",
    "pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-5 ResNet의 사전 학습된 모델 사용하기\n",
    "\n",
    "#python\n",
    "\n",
    "# 1. 로드 및 준비\n",
    "\n",
    "# fastai의 비젼 라이브러리의 모든것을 가져온다.\n",
    "from fastai.vision.all import *\n",
    "\n",
    "# 일반적으로 많이 사용하는 튜토리얼 코드\n",
    "# 데이터셋 로드\n",
    "# URLs.PETS는 fastai가 제공하는 url로 고양이와 강아지 이미지를 포함\n",
    "path = untar_data(URLs.PETS)\n",
    "# 이미지가 저장된 images 폴더의 경로\n",
    "# path에 /images를 추가해 디렉토리 내의 이미지 폴더 경로 지정\n",
    "path_imgs = path/'images'\n",
    "\n",
    "# 이미지 파일 라벨링 함수 정의\n",
    "# 이 함수는 이미지 파일의 이름을 받아 판단.\n",
    "# 문자열 x의 첫 번째[0] 문자를 가져온다.\n",
    "# .isupper()는 대문자일 때 True 소문자일 때 False로 반환\n",
    "def is_cat(x): return x[0].isupper()\n",
    "\n",
    "# 데이터블록 정의\n",
    "# ImageDataLoaders.from_name_func는 ImageDataLoaders 객체를 생성하는 메서드로, \n",
    "# 데이터를 학습용과 검증용으로 분할하고 전처리\n",
    "# path_imgs: 이미지 경로\n",
    "# get_image_files(path_imgs): 이미지 파일 리스트를 가져온다.\n",
    "# valid_pct=0.2: 20% 데이터를 검증용으로 분리\n",
    "# seed=42: 무작위성을 고정하여 동일한 분할 설정\n",
    "# label_func=is_cat: is_cat 함수를 사용해 라벨을 생성\n",
    "# item_tfms=Resize(224): 각 이미지를 224x224 픽셀로 크기 조정\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path_imgs, get_image_files(path_imgs), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "# 데이터셋 확인\n",
    "# max_n=9는 한 번에 9개의 이미지 보이게 설정\n",
    "# figsize=(7, 6)는 이미지 출력 크기를 지정\n",
    "dls.show_batch(max_n=9, figsize=(7, 6))\n",
    "\n",
    "\n",
    "\n",
    "# 2. 사전학습된 ResNet 모델 로드 및 학습\n",
    "# cnn_learner: CNN 모델을 사용해 학습기를 생성\n",
    "# dls는 데이터셋 로더 전달\n",
    "# resnet34 사전 학습된 모델을 사용해 학습기 생성\n",
    "# metrics=error_rate: 학습 중 사용할 성능 평가 지표를 설정(오류율 사용 지정)\n",
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "\n",
    "# 학습률 찾기 (최적의 학습률을 자동으로 찾아줌)\n",
    "# learn.lr_find(): 최적의 학습률을 찾는 함수\n",
    "learn.lr_find()\n",
    "\n",
    "# 모델 학습 (사전 학습된 모델에 대해 파인 튜닝)\n",
    "# learn.fine_tune(3): 사전 학습된 모델을 기반으로 3 epoch 동안 파인 튜닝을 진행\n",
    "learn.fine_tune(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. 모델 평가\n",
    "# show_results: 예측결과 시각화\n",
    "learn.show_results()\n",
    "\n",
    "# 혼동 행렬 (Confusion Matrix) 출력\n",
    "# ClassificationInterpretation.from_learner: 학습된 모델을 해석하고, 혼동 행렬을 생성\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Onesword",
   "language": "python",
   "name": "onesword"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
