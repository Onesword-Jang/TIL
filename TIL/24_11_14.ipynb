{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b07e1a3",
   "metadata": {},
   "source": [
    "# 내일배움캠프 35일차 TIL + Python, LLM 개인과제, prompt engineering\n",
    "\n",
    "## 목차\n",
    "\n",
    "오늘의 TIL 순서는\n",
    "\n",
    "1. **시작전 마음가짐**\n",
    "2. **Python 문제풀이**\n",
    "3. **개인과제 수행**\n",
    "4. **수준별 학습반**\n",
    "5. **회고**\n",
    "\n",
    "##### 학습 코드와 필기내용은 GITHUB링크를 이용해주세요\n",
    "- 개인과제(LLM)\n",
    "https://github.com/Onesword-Jang/mission/blob/main/%EC%B4%88%EA%B1%B0%EB%8C%80%20%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8%20%EC%97%B0%EA%B5%AC%20%EB%8F%99%ED%96%A5.ipynb\n",
    "\n",
    "----------------\n",
    "\n",
    "## 시작전 마음가짐\n",
    "오늘은 아직 잠이 덜 깬 상태로 시작하는 학습입니다.\n",
    "\n",
    "점점 추워지면서 몸이 왜이리 피곤에 절여지는거 같은지..\n",
    "\n",
    "일단 오늘의 학습은 어제와 비슷하지만 개인과제의 결과 출력을 조금 더 퀄리티 높게 나오게 만들어보고 다른 방법으로 개인과제를 다시 해보려고 합니다.\n",
    "\n",
    "굉장히 바쁜 하루일것 같습니다.\n",
    "\n",
    "그럼 학습을 시작하겟습니다.\n",
    "\n",
    "--------------\n",
    "\n",
    "## Python 문제풀이\n",
    "\n",
    "### 1. 조건 문자열\n",
    "- 처음 풀이가 1번 출력값이 틀림\n",
    "- f포맷팅을 이상하게 사용했나 싶어서 다르게 작성해보다가 안되서 GPT에게 물어보니 너무 긴 조건식을 보여주어서 가독성이 마음에 안들어 다른 방법을 찾아봄\n",
    "- eval함수: 문자열을 직접 조건식으로 평가하는 방법\n",
    "- eval함수를 사용해 완료\n",
    "\n",
    "```python\n",
    "# 첫 시도\n",
    "def solution(ineq, eq, n, m):\n",
    "    answer = '(f\"{n} {ineq}{eq} {m}\")'\n",
    "    if answer == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# eval함수 사용\n",
    "def solution(ineq, eq, n, m):\n",
    "    condition = f\"{n} {ineq}{'=' if eq == '=' else ''} {m}\"\n",
    "    return 1 if eval(condition) else 0\n",
    "```\n",
    "\n",
    "### 2. flag에 따라 다른 값 반환하기\n",
    "- 정답이 맞는데 답이 답이 나오지 않음\n",
    "- flag == 'true'를 flag == True 로 바꾸니 맞음\n",
    "\n",
    "```python\n",
    "# 나의 정답\n",
    "def solution(a, b, flag):\n",
    "    if flag == True:\n",
    "        return eval(f'{a} + {b}')\n",
    "    else:\n",
    "        return eval(f'{a} - {b}')\n",
    "\n",
    "# 간단한 정답\n",
    "def solution(a, b, flag):\n",
    "    return a + b if flag else a - b\n",
    "\n",
    "# lambda 활용\n",
    "\n",
    "solution = lambda a,b,f:a+b if f else a-b\n",
    "```\n",
    "\n",
    "### 3. 코드 처리하기\n",
    "- 문제 이해가 안감\n",
    "- 진짜 모르겟어서 GPT에게 답을 받음\n",
    "- 하지만 이해가 안감\n",
    "- 수업시간에 설명을 들어보아야할 듯\n",
    "- 준기님께서 설명을 해주셔서 이해 완료\n",
    "\n",
    "```python\n",
    "def solution(code):\n",
    "    mode = 0 \n",
    "    ret = \"\"  \n",
    "    \n",
    "    for idx in range(len(code)):\n",
    "        if code[idx] == \"1\":\n",
    "            mode = 1 - mode\n",
    "        else:\n",
    "            if mode == 0 and idx % 2 == 0:\n",
    "                ret += code[idx]\n",
    "            elif mode == 1 and idx % 2 == 1:\n",
    "                ret += code[idx]\n",
    "    \n",
    "    return ret if ret else \"EMPTY\"\n",
    "\n",
    "def solution(code):\n",
    "    mode = 0\n",
    "    ret = \"\"\n",
    "    for idx in range(len(code)):\n",
    "        if code[idx] =! 1 and idx % 2 == 0:\n",
    "            ret += code[idx]\n",
    "            if code[idx] == 1:\n",
    "                mode = 1\n",
    "        else:\n",
    "            if code[idx] =! 1 and idx % 2 == 1:\n",
    "                ret += code[idx]\n",
    "                if code[idx] == 1:\n",
    "                    mode = 0\n",
    "                    \n",
    "    return ret\n",
    "```\n",
    "\n",
    "----------------------\n",
    "\n",
    "## 개인과제 (LLM)\n",
    "\n",
    "### 수정 사항\n",
    "1. 전체코드에 대한 이해도가 낮아 자세한 내용을 정리해보아야할듯\n",
    "2. 백업 스토어 설정에서 InMemoryDocstore를 사용해보기\n",
    "3. 리트리버 변환에서 다른 변환 방법 찾아보고 적용 및 비교해보기\n",
    "4. 답변 방식을 바꾸는 프롬프트 방법 찾아보기\n",
    "5. 대화형 Chat봇 코드와 비교해 보았을 때 오히려 가독성이 떨어지게 출력이 되어 프롬프트 수정이 필요해 보임\n",
    "\n",
    "### 수정 현황\n",
    "\n",
    "#### 1. 전체코드 내용 정리\n",
    "- 전체 내용의 라이브러리, 패키지, 파라미터, 코드의 흐름에 대한 내용을 정리했습니다.\n",
    "\n",
    "> 아직 다음 단계를 시도해보지 못했습니다. \n",
    "\n",
    "#### 공부하며 추가 수정이 필요한 부분\n",
    "- 백터 스토어 생성에서 FAISS.from_documents 대신 FAISS.from_embeddings 사용해서 결과 비교해보기\n",
    "- 랭스미스 API키 받아서 LLM평가해보기\n",
    "\n",
    "\n",
    "\n",
    "---------\n",
    "\n",
    "## 수준별 학습반 (prompt engineering)\n",
    "\n",
    "### Prompt Development Cycle의 평가기준\n",
    "\n",
    "#### 1. 사람이 평가하는 방법\n",
    "1) LMSys Chatbot Arena(https://chat.lmsys.org/)\n",
    " - 동일 질문에 대해 익명의 2개 모델의 답변 중 선택할 수 있는 싸이트 \n",
    " - 승/패/무 투표 이후에 모델명 공개\n",
    " - 각 모델에 대한 랭킹 존재\n",
    "\n",
    "#### 2. LLM 모델이 평가하는 방법\n",
    "1) Model Based Evaluation\n",
    " - GPT-4 같은 Strong LLM을 통해 평가하는 방법\n",
    " - Pairwise Comparison: 답변 2개 중 결정하게 만든다.\n",
    " - Single Answer Grading: 답변에 점수를 매긴다.\n",
    " - Reference-Guided Grading: 예시 답변을 주고 점수를 매긴다.\n",
    "\n",
    "#### 3. 코드로 평가하는 방법\n",
    "- 코드 로직을 통한 평가 방법\n",
    " 1) Accuracy, Precision, Recall 등\n",
    " 2) ROUGE: 요약 모델에 사용\n",
    " 3) BLUE: 기계 번역 자동 평가 방법\n",
    " 4) Exact Match, String Match\n",
    " \n",
    "#### 4. 결론\n",
    "- 사람이 직접 평가하는 것이 가장 좋다.\n",
    "- 모델이 평가하는 방법도 충분히 사용 가능하다\n",
    "- 정량적인 평가와 정성적인 평가 모두 하는게 가장 이상적인 케이스\n",
    "\n",
    "### Prompt engineering의 기법들\n",
    "\n",
    "#### 1. few shot\n",
    "- 참고 할 수 있는 정답 사례들을 Prompt에 추가하여 성능을 높이는 방법\n",
    "- 모델 사이즈가 어느정도 커야지 효과가 특출나다.\n",
    "- 사전 훈련 단계에서 언어 모델이 패턴을 인지하고 적응하는 능력이있다.\n",
    "- **In-Context Learning**이라고도 불림\n",
    "\n",
    "#### 2. Chain-of-Thought\n",
    "- Few Shot에 추가로 문제 해결 과정(Reasoning)도 같이 Prompt에 추가하는 방식\n",
    "- CoT 응용 케이스\n",
    " 1. Self-Consistency: 여러 번의 다양한 CoT 과정을 거쳐 그 중 베스트를 선정\n",
    " 2. Generated Knowledge: 질문을 통해 상식을 끄집어내어 더 정확하게 대답하는 방법\n",
    " 3. Least-to-Most: 질문 A를 바로 물어보지 않고 질문 a, b로 쪼개서 물어보는 분할 정복 방법\n",
    " 4. Prompt Chaining: Prompt A의 Output A를 Prompt B에 사용하는 방법\n",
    " 5. ReAct: Reasoning 외에도 Action까지 추가하는 방법\n",
    " \n",
    "---------------\n",
    "\n",
    "## 회고\n",
    "\n",
    "**전체적으로**\n",
    "\n",
    "오늘은 집중이 잘 안되는 하루였습니다.\n",
    "\n",
    "파이썬 문제도 어려워서 시간이 꽤 걸렸고 개인과제 목표도 전부 달성하지 못했습니다.\n",
    "\n",
    "하지만 수준별 학습반 수업은 흥미롭고 많은 사람들의 질문에 많은 공부가 되었습니다.\n",
    "\n",
    "내일을 개인과제의 목표를 모두 수행해보겟습니다.\n",
    "\n",
    "**Python 문제풀이를 하며**\n",
    "\n",
    "파이썬 문제를 풀 때 가장 중요시 생각하는게 나의 머리로만 풀자입니다.\n",
    "\n",
    "오늘 문제들은 생각이 나지않아 GPT의 도움을 많이 받았습니다.\n",
    "\n",
    "GPT의 도움을 받아도 코드를 그대로 따라 쓰는게 아닌 어떤 흐름인지 간단하게 파악하고 다시 혼자 코드를 작성하면서 학습 중입니다.\n",
    "\n",
    "또한 GPT의 답변이 마음에 들지 않는다면 과감히 다른 방법으로 해결하려합니다.\n",
    "\n",
    "문제 3번은 GPT의 설명을 보아도 이해가 가지않았는데 같은 팀원인 준기님의 설명으로 빠르게 이해를 할 수 있었습니다.\n",
    "\n",
    "**개인 과제를 진행하며**\n",
    "\n",
    "코드는 어제 다 짜놓은 상태지만 거의 따라치다 싶이하여서 코드들의 각 기능에 대해서 공부를 하였습니다.\n",
    "\n",
    "공부를하며 느끼는 의문점들을 메모해 놓았고 그것을 해결하기 위한 방법들을 적용하는 것이 내일 목표입니다.\n",
    "\n",
    "또한 LLM모델을 다른 방식으로 만들어보고 두가지 모델을 비교하는게 최종 목적입니다.\n",
    "\n",
    "**수준별 학습 수업을 들으며**\n",
    "\n",
    "오늘은 실습 보다 이론 위주의 수업이였습니다.\n",
    "\n",
    "제공되는 강의 내용과 비슷하지만 한 가지의 주제(Prompt)를 깊게 이해하는데 도움이 되었으며 확실히 흥미를 가지고 수업에 임하니 이해가 잘되고 집중력이 높았습니다.\n",
    "\n",
    "또한 간단한 실습을 진행하였는데 반복해서 치다보니 영타가 빨라지고 실습하는 코드를 완벽하진 않지만 외우게 되었습니다.\n",
    "\n",
    "이렇게 천천히 다져가면 언젠간 단단한 지식이 되어 필요한 지식을 꺼내려할 때 무너지지 않을 것 같습니다.\n",
    "\n",
    "**감사합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313ff24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jang",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
