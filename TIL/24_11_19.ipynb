{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ec433c",
   "metadata": {},
   "source": [
    "# 내일배움캠프 38일차 TIL + Python, LLM특강, 개인과제(완료)\n",
    "\n",
    "## 목차\n",
    "\n",
    "오늘의 TIL 순서는\n",
    "\n",
    "1. **시작전 마음가짐**\n",
    "2. **Python 문제풀이**\n",
    "3. **LLM 특강**\n",
    "4. **개인과제 수행**\n",
    "5. **회고**\n",
    "\n",
    "##### 학습 코드와 필기내용은 GITHUB링크를 이용해주세요\n",
    "- https://github.com/Onesword-Jang/mission/blob/main/Prompts/base.ipynb\n",
    "--------\n",
    "\n",
    "## 시작전 마음가짐\n",
    "오늘은 외출 예정이여서 6시 20분 부터 학습을 시작하였습니다.\n",
    "\n",
    "시작은 개인과제의 도전과제 마무리 하는 것을 목표로 진행하고 도전과제를 마무리하면 Python문제풀이, LLM특강 순서로 진행하겟습니다.\n",
    "\n",
    "새벽부터 시작하서 조금 피곤하지만 정신 차리고 학습을 시작하겟습니다.\n",
    "\n",
    "-----------\n",
    "## Python 문제풀이\n",
    "\n",
    "### 1. 수 조작하기 2\n",
    "- if문은 이해가가는데 for문과 diff정의가 이해가 안감\n",
    "\n",
    "```python\n",
    "def solution(numLog):\n",
    "    # 결과 문자열을 저장할 변수\n",
    "    result = \"\"\n",
    "    \n",
    "    # numLog 배열의 차이를 순회하며 문자열을 구성\n",
    "    for i in range(1, len(numLog)):\n",
    "        diff = numLog[i] - numLog[i - 1]\n",
    "        if diff == 1:\n",
    "            result += \"w\"\n",
    "        elif diff == -1:\n",
    "            result += \"s\"\n",
    "        elif diff == 10:\n",
    "            result += \"d\"\n",
    "        elif diff == -10:\n",
    "            result += \"a\"\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "### 2. 수열과 구간 쿼리3\n",
    "\n",
    "```python\n",
    "def solution(arr, queries):\n",
    "    # 각 쿼리의 [i, j]에 따라 arr의 값을 교환\n",
    "    for i, j in queries:\n",
    "        arr[i], arr[j] = arr[j], arr[i]\n",
    "    return arr\n",
    "```\n",
    "\n",
    "### 3. 수열과 구간 쿼리2\n",
    "- 빈 리스트를 왜 2개 정의하는지 이해가 안감\n",
    " - 최솟값을 구해야해서 2개를 청의하는 건가?\n",
    "\n",
    "- query마다 순서대로 s ≤ i ≤ e인 모든 i에 대해 k보다 크면서 가장 작은 arr[i]\n",
    " - for i in range(s,e+1): if arr[i] > k:    answer.append(min(l))\n",
    "\n",
    "```python\n",
    "# 내가 틀린 문제\n",
    "def solution(arr, queries):\n",
    "    answer = []\n",
    "    for i in range(1, len(arr)):\n",
    "        for a,b,c in queries:\n",
    "            if a <= arr[i] <= b and arr[i] > c:\n",
    "                answer.append(min(arr[i]))\n",
    "            else:\n",
    "                answer.append(-1)\n",
    "        \n",
    "    return answer\n",
    "\n",
    "# solution검색하고 틀림\n",
    "def solution(arr, queries):\n",
    "    answer = []\n",
    "    for a, b, c in queries:\n",
    "        # 조건에 맞는 값 중 가장 작은 값을 찾기\n",
    "        valid_values = [num for num in arr if a <= num <= b and num > c]\n",
    "        if valid_values:\n",
    "            answer.append(min(valid_values))  # 가장 작은 값 추가\n",
    "        else:\n",
    "            answer.append(-1)  # 조건에 맞는 값이 없으면 -1 추가\n",
    "    return answer\n",
    "\n",
    "# solution 검색 후\n",
    "def solution(arr, queries):\n",
    "    answer = []\n",
    "    for s, e, k in queries:\n",
    "        l = []\n",
    "        for i in range(s,e+1):\n",
    "            if arr[i] > k:\n",
    "                l.append(arr[i])\n",
    "        if l:\n",
    "            answer.append(min(l))\n",
    "        else:\n",
    "            answer.append(-1)\n",
    "\n",
    "    return answer\n",
    "```\n",
    "------------\n",
    "\n",
    "## 개인과제(LLM)\n",
    "\n",
    "### 코드 수정 및 추가\n",
    "\n",
    "#### 1. txt파일로 프롬프트 적용\n",
    "1. select_prompt 정의(items, get, open, read)\n",
    " - items: 키, 값을 튜플로 묶어 반환\n",
    " - get: choice(사용자 입력 값)을 키로 값(prompt)를 반환\n",
    " - open:파일 열어서 읽기 모드('r')\n",
    " - read: 파일 불러오기\n",
    "2. langchain.prompts.chat 정의(ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate )\n",
    " - ChatPromptTemplate: 다른 두 템플릿을 결합해서 대화형식 메시지로 구성\n",
    " - SystemMessagePromptTemplate: 모델의 역할(system_message) 지정\n",
    " - HumanMessagePromptTemplate: 사용자의 질문({user_input}) 지정\n",
    " \n",
    " \n",
    "#### 2. RAG체인 구성 변환\n",
    "\n",
    "1) LLMChain 추가\n",
    " - 템플릿을 기반으로 여러 메시지를 조합하고 모델에 전달\n",
    " - contextual_prompt을 처리하고, 모델을 실행하는 방식으로 변경\n",
    "\n",
    "\n",
    "2) ContextToText 클래스 수정\n",
    " - LLMChain에 맞게 RunnablePassthrough를 상속 받지않고, 단순 메서드 정의\n",
    "\n",
    "3) 실행방식 변경(파이프라인=>get_contextual_response())\n",
    " - 사용자의 질문에 대한 컨텍스트를 가져오고, 이를 chat_prompt 템플릿에 맞게 포맷팅하여 모델에 전달\n",
    " - retriever.get_relevant_documents(query): 질문에 맞는 문서들을 검색\n",
    " - ContextToText 클래스에서 변환된 텍스트는 formatted_messages에 담겨 모델에 전달\n",
    "\n",
    "#### 3. 반복 질문 삭제\n",
    "- while루프 제거\n",
    "\n",
    "#### 4. 답변 txt파일로 저장 코드 추가\n",
    "- output_folder: r포맷팅으로 저장 경로 지정\n",
    "- os.makedirs: 폴더안에 저장 지정\n",
    "- timestamp: 현재 년,월,일,시,분,초를 txt파일 이름으로 지정\n",
    "- open: 쓰기모드('w\")를 지정\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "## LLM 특강 3일차\n",
    "\n",
    "### 1. Local LLM\n",
    "\n",
    "- VRAM: Video RAM으로 그래픽 카드에서 사용하는 램, 일반적인 컴퓨터에서는 RAM과 별도로 운영 되며 그래픽카드에 포함되어있다.\n",
    " - 로컬에서 사용하기 위해선 16GB의 VRAM공간이 필요\n",
    " \n",
    "- LLM 모델 축소 방법\n",
    " - 양자화: 실수형 파라미터들을 정수형 파라미터로 바꿔서 사용(성능의 저하가 있음)\n",
    " - sLLM/SLM:애초에 작은 사이즈를 염두에 두고 학습한 언어모델(Gemma, phi3)\n",
    " \n",
    "- 실습 (ollama): 다운과 사용이 프롬프트로 한다.\n",
    " - ollama: 로컬 환경에 llm모델을 다운받아 사용가능하고 파인튜닝 등의 작업 가능\n",
    " - LM Studio: hugging face에 올라와있는 다양한 유저 커스텀 모델을 간단하게 사용 가능(파인튜닝 등의 복잡한 단계는 hugging face에서 가능)\n",
    "\n",
    "> vram용량 부족 시 llm모델을 끄면 된다.\n",
    "\n",
    "```python\n",
    "# 오라마 인터페이스 다운\n",
    "\n",
    "# bash\n",
    "ollama run llama3.2 # 모델마다 필요 vram크기가 다름\n",
    "\n",
    "# send a massage\n",
    "Hi how are you\n",
    "# 답변\n",
    "Hi! i'm .....\n",
    "\n",
    "# 1. LM Studio 다운\n",
    "# 2. 원하는 모델을 검색해 유저들이 올린 모델 다운\n",
    "# 3. LM Studio 인터페이스에서 모델 적용 및 프롬프트 작업, chat기능을 사용할 수 있다.\n",
    "```\n",
    "\n",
    "------------\n",
    "\n",
    "## 회고\n",
    "오늘은 피곤해서 전체적으로 쓰겟습니다.\n",
    "\n",
    "아침 6시부터 시작한 학습은 매우 힘들었습니다.\n",
    "\n",
    "외출을 하러가서도 쪽잠을 자는 등으로 컨디션을 겨우 유지했습니다.\n",
    "\n",
    "그래도 개인과제의 도전과제까지 완료하였고 제출했습니다. 기쁨니다.\n",
    "\n",
    "LLM특강도 로컬에서 LLM을 사용하는 방법에 대하여 배웠는데 저는 환경이 되지않아 실습은 해보지 못했습니다.\n",
    "\n",
    "Python문제풀이는 점점 어려워지고있는것을 체감합니다.\n",
    "\n",
    "이제는 이해가 안되는 부분도 많아져서 강의 때 열심히 듣고 질문해야겟습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c96989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jang",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
