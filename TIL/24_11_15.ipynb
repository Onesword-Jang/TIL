{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d791bff",
   "metadata": {},
   "source": [
    "# 내일배움캠프 36일차 TIL + Pytohn,특강(LLM, API), 개인과제(LLM), prompt engineering\n",
    "\n",
    "## 목차\n",
    "\n",
    "오늘의 TIL 순서는\n",
    "\n",
    "1. **시작전 마음가짐**\n",
    "2. **Python 문제풀이**\n",
    "3. **LLM 특강**\n",
    "4. **개인과제 수행**\n",
    "5. **수준별 학습반**\n",
    "6. **회고**\n",
    "\n",
    "##### 학습 코드와 필기내용은 GITHUB링크를 이용해주세요\n",
    "- prompt engineering\n",
    "https://github.com/Onesword-Jang/mission/blob/main/prompt_engineering1.ipynb\n",
    "\n",
    "-----------\n",
    "\n",
    "## 시작전 마음가짐\n",
    "오늘의 학습은 개인과제에 집중을 할 것입니다.\n",
    "\n",
    "최대한 개인과제에 필요하고 메모해 놓았던 부분들을 실행시키는 것이 목표입니다.\n",
    "\n",
    "python문제와 수준별학습반의 prompt강의도 궁금하네요\n",
    "\n",
    "학습을 시작하겟습니다.\n",
    "\n",
    "---------------\n",
    "\n",
    "## Python 문제풀이\n",
    "\n",
    "### 1. 등차수열의 특정 항 더하기\n",
    "- range함수로 등차수열을 정의 했는데 값이 true, false이면 정의가 안됨\n",
    "- 등차 수열을 계산하는 코드식 찾아보고 해결\n",
    "\n",
    "```python\n",
    "# 첫 번째\n",
    "def solution(a, d, included):\n",
    "    answer = range(a, len(included), d)\n",
    "    for i in rnage(len(included)):\n",
    "        if included[i]:\n",
    "            return sum(answer[i + 1])\n",
    "        \n",
    "# 두 번째\n",
    "def solution(a, d, included):\n",
    "    answer = 0\n",
    "    for i in range(len(included)):\n",
    "        if included[i]:  \n",
    "            answer += a + i * d  \n",
    "    return answer\n",
    "```\n",
    "\n",
    "### 2. 주사위 게임\n",
    "- random함수를 사용해서 풀어보려 했으나 random으로 출력한 값을 변수로 지정하는 방법을 찾지못함\n",
    "- 하나씩 정의해가면 해결\n",
    "\n",
    "```python\n",
    "def solution(a, b, c):\n",
    "    ran_1 = a + b + c\n",
    "    rna_2 = a**2 + b**2 + c**2\n",
    "    ran_3 = a**3 + b**3 + c**3\n",
    "\n",
    "    if a == b == c:\n",
    "        return ran_1 * rna_2 * ran_3\n",
    "    if a == b or b == c or a == c:\n",
    "        return ran_1 * rna_2\n",
    "    else:\n",
    "        return ran_1\n",
    "```\n",
    "\n",
    "### 3. 원소들의 곱과 합\n",
    "- 고민은 조금있었지만 완료\n",
    "\n",
    "```python\n",
    "def solution(num_list):\n",
    "    answer_1 = sum(num_list)**2\n",
    "    \n",
    "    answer_2 = 1\n",
    "    for num in num_list:\n",
    "        answer_2 *= num\n",
    "\n",
    "    if answer_1 > answer_2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "```\n",
    "\n",
    "---------\n",
    "\n",
    "## LLM 특강 1강\n",
    "\n",
    "### 1. LLM은 어떻게 딥러닝을 통해 구현될 수 있었을까?\n",
    "- DNN(딥러닝): 입력층 -((가중치)> 은닉층....->출력층\n",
    "- 언어 모델에는 RNN을 보통 사용한다.\n",
    "- 과정: 데이터가 커지면서 기울기 소실문제가 발생해 해결하기 위한 방법이 나옴\n",
    " - LSTM\n",
    " - GRU\n",
    " - 하지만 RNN의 구조적인 한계(장기 의존성, 기울기 소실 문제)로 완전히 극복하지 못함\n",
    " - 그래서 Attention 기법의 도입\n",
    "\n",
    "- Transformers: RNN을 빼버리고 Attention만을 사용한 모델을 만들었는데 성능이 더욱 뛰어났다. \n",
    " - 앞의 노드 점수를 계산할 필요가 없어짐\n",
    " - 모든 노드의 점수를 동시에 계산할 수 있게 됨(GPU)\n",
    " - 장기의존성, 기울기 소실문제 개선\n",
    "- 결론: Transformers를 이용해서 데이터 사용양을 늘리수있었고 그로인해 LLM을 만들 수 있게 되었다. \n",
    "\n",
    "### 2. LLM은 어떤식으로 배우게 되나요?\n",
    "- 공식 문서를 보고 코드를 쓸 줄 알아야한다.\n",
    "\n",
    "### 3. LLM활용의 기본적인 컨셉트\n",
    "- Text Completion(텍스트 완성)에 특히 강점을 가지고있음\n",
    " - 맥락(Context)를 읽고 다음에 올 단어를 예측하여 문장을 완성하는 것\n",
    " - Context로 줄 수 있는 토큰의 사이즈가 커지니 다양한 일들이 가능해짐 ex) Prompt\n",
    "\n",
    "- Prompt: 사용자 질문만이 아니라 Prompt에 설정 된 문맥까지 다 읽고 기능\n",
    " - user\n",
    " - System\n",
    " - Assistant\n",
    " \n",
    "- Token 단위로 prompt를 읽어 온다.\n",
    "\n",
    "### 4. LLM 사용해보기\n",
    "- OpenAI Platform의 공식 문서를 사용해서 코드 및 파라미터의 정보를 읽는 방법에 대한 내용으로 진행 되었습니다.\n",
    "\n",
    "- 실습 진행한 링크\n",
    "https://colab.research.google.com/drive/17i_9NgVYpYhEQZCM7V6brIjhXxPCsd9H#scrollTo=PcBAopj27VMs\n",
    "\n",
    "--------\n",
    "\n",
    "## 개인과제 (LLM)\n",
    "\n",
    "### 수정 필요!\n",
    "1. 백업 스토어 설정에서 InMemoryDocstore를 사용해보기\n",
    "2. 리트리버 변환에서 다른 변환 방법 찾아보고 적용 및 비교해보기\n",
    "3. 답변 방식을 바꾸는 프롬프트 방법 찾아보기\n",
    "4. 대화형 Chat봇 코드와 비교해 보았을 때 오히려 가독성이 떨어지게 출력이 되어 프롬프트 수정이 필요해 보임\n",
    "5. 백터 스토어 생성에서 FAISS.from_documents 대신 FAISS.from_embeddings 사용해서 결과 비교해보기\n",
    "6. 랭스미스 API키 받아서 LLM평가해보기\n",
    "\n",
    "### 수정 진행!\n",
    "#### 1. InMemoryDocstore를 사용해보기\n",
    "```python\n",
    "# 벡터 스토어 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "vector_dim = len(embeddings.embed_query(\"example text\")) \n",
    "index = faiss.IndexFlatL2(vector_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "```\n",
    "#### 2. 파라미터 조정\n",
    "```python\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0.3, max_tokens = 1000, stream = True)\n",
    "\n",
    "```\n",
    "#### 3. 프롬프트에 추가한 명령\n",
    "\n",
    "- system: 인공지능 모델 연구자이십니다. 이 문서에서는 발전, 과제 및 주요 기여를 포함하여 초대형 언어 모델의 최신 연구 동향을 설명합니다. 귀하의 임무는 문서를 분석하고 상세하고 통찰력 있는 답변을 제공하는 것입니다.\n",
    "- user: 본 문서에 언급된 주요 동향과 연구 결과를 중심으로 포괄적인 답변을 부탁드립니다.\n",
    "\n",
    "```python\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an artificial intelligence model researcher. The document describes the latest research trends in super-large language models, including advancements, challenges, and key contributions. Your task is to analyze the document and provide a detailed and insightful response.\"),\n",
    "    (\"user\", \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer: Please provide a comprehensive response, focusing on the key trends and research findings mentioned in the document.\")\n",
    "])\n",
    "```\n",
    "------\n",
    "\n",
    "## 수준별 학습반\n",
    "\n",
    "### Prompt 점수 측정 방법\n",
    "- baseline prompt 작성\n",
    "- 다른 모델 prompt의 답변을 저장한다.\n",
    "- Rouge, G-Eval 사용하여 점수를 받고 프롬프트를 수정하며 점수를 높여간다.\n",
    "\n",
    "- 결론: 실습코드를 중간에 놓쳐서 완벽하게 따라해보지는 못했지만 어느정도 이해가 되는 수업이였습니다. 놓친 부분은 주말에 1~3강 복습을 해보고 개인과제에 적용을 하고 남은 기간동안 프롬프트 엔지니어링 과정을 문서화하는것을 복표로 해보아야겟습니다.\n",
    "\n",
    "---------\n",
    "\n",
    "## 회고\n",
    "**전체적으로**\n",
    "\n",
    "오늘 학습은 꽤나 알찻다고 생각합니다.\n",
    "\n",
    "오전 10시에 진행한 LLM특강 오후 7시에 진행한 API키 특강 오늘은 특강이 2개나 진행 되었고 수준별 학습반에서도 prompt engineering에 대한 강의가 있었습니다.\n",
    "\n",
    "모든 정보를 이해했다고는 할 수 없지만 대부분은 이해가 가능했다고 말할 수 있습니다.\n",
    "\n",
    "**Python 문제풀이를 하며**\n",
    "아직 기본기가 부족한 것 같습니다.\n",
    "\n",
    "잠시 헷갈린거지만 바로 행동으로 옮겨지지 않은건데요 그것이 바로 기본인 리스트를 활용하는 방법과 연산기호를 사용해 결과를 가져오는 부분이였습니다.\n",
    "\n",
    "지금까지 문제를 풀며 나온 작성법들과 혼동이 와서 그런 것 같습니다.\n",
    "\n",
    "다음에는 이러한 기본적인 부분은 바로 사용방벙이 생각 날 만큼 학습을 진행야할듯합니다.\n",
    "\n",
    "**특강을 들으며**\n",
    "오늘은 2가지의 특강을 들었습니다.\n",
    "\n",
    "오전의 **LLM특강**은 지금까지 궁금했던 LLM과 딥러닝의 연관성에 대한 내용이 나와서 흥미롭고 높은 이해도로 가져갈 수 있었습니다.\n",
    "\n",
    "**API특강**은 우리가 친숙하게 사용했던 싸이트들의 API키를 발급 받고 사용방법 및 공식 API키 관련 문서읽는 방법에 대하여 알려주셨습니다.\n",
    "\n",
    "각 싸이트마다 조금씩 다른 점이있지만 API키를 불러오는 방법의 진행방식이 매우 비슷하다 생각 들었습니다.\n",
    "\n",
    "**개인과제를 진행하며**\n",
    "\n",
    "개인과제 LLM에 대한 진도는 크게 나가지 않았지만 지금까지 진행하며 필요하다고 생각한 수정이 필요한 부분들이 필요한지 다음 단계에서 진행해야하는 것인지에 대해서 파악할 수 있었습니다.\n",
    "\n",
    "또한 내가 만든 RAG체인을 활용한 대화형 LLM모델에 직접적으로 프롬프팅 엔지니어링을 하는 방법을 알게 되었습니다.\n",
    "\n",
    "**수준별 학습반 수업을 들으며**\n",
    "\n",
    "실습코드를 중간에 놓쳐서 완벽하게 따라해보지는 못했지만 어느정도 이해가 되는 수업이였습니다. \n",
    "\n",
    "놓친 부분은 주말에 1~3강 복습을 해보고 개인과제에 적용을 하고 남은 기간동안 프롬프트 엔지니어링 과정을 문서화하는것을 복표로 해보아야겟습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b67c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jang",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
